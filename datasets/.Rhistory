p <- length(model$coefficients)
n <- length(residuals)
# Bonferroni test
bonferroni <- list(which(abs(residuals) > qt(0.975, n-2) * sd(residuals)))
# Cook's distance
cook <- list(which(cooks.distance(model) > 4/(n - p - 1)))
cook2 <- list(which(cooks.distance(model) > 4/n))
# dfbetas
dfbetas <- list(which(abs(dfbetas(model)) > 2/sqrt(n)))
# dffits
dffits <- list(unique(which(dffits(model) > 2 * sqrt(p/n))))
dffits2 <- list(which(abs(dffits(model)) > 2 * sqrt(p * (n - p)/n)))
# Leverage points
leverage_criteria_1 <- 0.2
leverage_criteria_2 <- 2 * p/n
leverage <- list(which(hat_values > leverage_criteria_1 | hat_values > leverage_criteria_2))
# Convert the lists to character strings
bonferroni_str <- toString(unlist(bonferroni))
cook_str <- toString(unlist(cook))
cook_str2 <- toString(unlist(cook2))
dfbetas_str <- toString(unlist(dfbetas))
dffits_str <- toString(unlist(dffits))
dffits_str2 <- toString(unlist(dffits2))
leverage_str <- toString(unlist(leverage))
# Creating a data frame to store the test results
results <- data.frame(
Test_Criteria = c("Bonferroni", "Cook 1", "Cook 2", "DFBetas", "DFFits", "DFFits2", "Leverage"),
Influential_Points = c(bonferroni_str, cook_str, cook_str2, dfbetas_str, dffits_str, dffits_str2, leverage_str),
stringsAsFactors = FALSE
)
return(results)
}
outliers_influential_test(modelo.cigar.1)
list(which(abs(dffits(modelo.cigar.1)) > 2 * sqrt(p * (n - p)/n)))
df <- modelo.cigar.1$df.residual
dffits_crit = 2 * sqrt( p/n )
dffits <- dffits( modelo.cigar.1 )
df <- data.frame( obs = names( dffits ), dffits = dffits )
ggplot( df, aes( y = dffits, x = obs ) ) +
geom_point( color = '#013ADF' ) +
geom_hline( yintercept = c( dffits_crit, -dffits_crit ),
linetype = 'dashed' ) +
labs( title = 'DFFITS',
subtitle = 'Observaciones Influyentes',
x = 'Orden de Observación',
y = 'DFFITS') +
theme_bw()
lev <- hatvalues(modelo.cigar.1)
unique(which(lev>0.2))
lev <- hatvalues(modelo.cigar.1)
unique(which(lev>2*p/n))
outliers_influential_test(modelo.cigar.1)
ols_plot_resid_stud_fit(modelo.cigar.1)
#### INFLUYENTES
##### Cook
ols_plot_cooksd_bar(modelo.cigar.1)
ols_plot_dfbetas(modelo.cigar.1)
ols_plot_dffits(modelo.cigar.1)
ols_plot_resid_stand(modelo.cigar.1)
ols_plot_resid_lev(modelo.cigar.1)
test_supuestos <- function( my_model, nivel_significancia = 0.05 ) {
suppressMessages( require(lmtest) )
suppressMessages( require(car) )
#Shapiro Test
t_sha <- shapiro.test( my_model$residuals )
t_sha_obs <- ifelse( t_sha$p.value > nivel_significancia,
"Los residuos son normales.",
"Los residuos NO son normales.")
#BP Test
t_bp <- bptest( my_model )
t_bp_obs <- ifelse( unname(t_bp$p.value) > nivel_significancia,
"Homocedasticidad. La varianza de los residuos es constante.",
"Heterocedasticidad. La varianza de los residuos NO es constante.")
#Durbin-Watson Test
t_dwt <- durbinWatsonTest( my_model )
t_dwt_obs <- ifelse( t_dwt$p > nivel_significancia,
"No hay autocorrelación. Los residuos son independientes.",
"Hay autocorrelación. Los residuos NO son independientes.")
resultados <- data.frame(
Prueba = c("Shapiro", "Breusch-Pagan", "Durbin-Watson"),
P_Value = c(t_sha$p.value, unname(t_bp$p.value), t_dwt$p)
)
resultados$H0 <- ifelse( resultados$P_Value > nivel_significancia, "No rechazada", "Rechazada" )
resultados$Observaciones <- ifelse( resultados$Prueba == "Shapiro", t_sha_obs,
ifelse( resultados$Prueba == "Breusch-Pagan", t_bp_obs, t_dwt_obs ) )
return(resultados)
}
analizar_vif <- function(modelo) {
suppressMessages( library( car ) )
vif_values <- vif(modelo)
categorias <- ifelse(vif_values <= 1, "Ausente",
ifelse(vif_values <= 5, "Moderada",
"Significativa"))
resultado <- data.frame(Variables = names(vif_values),
VIF = vif_values,
Multicolinealidad = categorias,
row.names = 1:length(vif_values))
return(resultado)
}
outliers_influential_test <- function(model) {
library(dplyr)
# Extracting model information
fitted_values <- model$fitted.values
residuals <- model$residuals
hat_values <- lm.influence(model)$hat
p <- length(model$coefficients)
n <- length(residuals)
# Bonferroni test
bonferroni <- list(which(abs(residuals) > qt(0.975, n-2) * sd(residuals)))
# Cook's distance
cook <- list(which(cooks.distance(model) > 4/(n - p - 1)))
cook2 <- list(which(cooks.distance(model) > 4/n))
# dfbetas
dfbetas <- list(which(abs(dfbetas(model)) > 2/sqrt(n)))
# dffits
dffits <- list(unique(which(dffits(model) > 2 * sqrt(p/n))))
dffits2 <- list(which(abs(dffits(model)) > 2 * sqrt(p * (n - p)/n)))
# Leverage points
leverage_criteria_1 <- 0.2
leverage_criteria_2 <- 2 * p/n
leverage <- list(which(hat_values > leverage_criteria_1 | hat_values > leverage_criteria_2))
# Convert the lists to character strings
bonferroni_str <- toString(unlist(bonferroni))
cook_str <- toString(unlist(cook))
cook_str2 <- toString(unlist(cook2))
dfbetas_str <- toString(unlist(dfbetas))
dffits_str <- toString(unlist(dffits))
dffits_str2 <- toString(unlist(dffits2))
leverage_str <- toString(unlist(leverage))
# Creating a data frame to store the test results
results <- data.frame(
Test_Criteria = c("Bonferroni", "Cook 1", "Cook 2", "DFBetas", "DFFits", "DFFits2", "Leverage"),
Influential_Points = c(bonferroni_str, cook_str, cook_str2, dfbetas_str, dffits_str, dffits_str2, leverage_str),
stringsAsFactors = FALSE
)
return(results)
}
test_supuestos(modelo.cigar.1)
modelo.cigar.robusto <- lmrob(Sales ~ Age + Income + Price, data = cigar[,-c(1)])
suppressMessages( library( readxl ) )
suppressMessages( library( performance ) )
suppressMessages( library( ggplot2 ) )
suppressMessages( library( MASS ) )
suppressMessages( library( olsrr ) )
suppressMessages( library( leaps ) )
suppressMessages( library( gamlss ) )
suppressMessages( library( readr ) )
suppressMessages( library( gridExtra ) )
suppressMessages( library( vcd ) )
suppressMessages( library( ROCR ) )
suppressMessages( library( ResourceSelection ) )
suppressMessages( library( MLmetrics ) )
suppressMessages( library( caret ) )
suppressMessages( library( corrplot ) )
suppressMessages( library( PerformanceAnalytics ) )
suppressMessages( library( robustbase ) ) #lmrob
modelo.cigar.robusto <- lmrob(Sales ~ Age + Income + Price, data = cigar[,-c(1)])
resultados_robustos <- summary(modelo.cigar.robusto)
resultados_robustos
test_supuestos(modelo.cigar.robusto)
modelo.cigar.robusto$residuals
durbinWatsonTest( modelo.cigar.robusto )
durbinWatsonTest( residuals(modelo.cigar.robusto) )
durbinWatsonTest(residuals(modelo.cigar.robusto), method = "robust")
shapiro.test(modelo.cigar.robusto)
shapiro.test(modelo.cigar.robusto$residuals)
densidad <- c(.90, .87, .90, .86, .89, .91,
.93, .88, .87, .79, .82, .80, # general
.91, .90, .80, .88, .82, .83,
.86, .85, .80, .86, .85, .85) # torta
tipo_harina <- c(rep("general", 12),
rep("para_tortas", 12))
conc_azucar <- c(rep("0", 3), rep("50", 3),
rep("75", 3), rep("100", 3),
rep("0", 3), rep("50", 3),
rep("75", 3), rep("100", 3))
galletas <- data.frame(densidad, tipo_harina, conc_azucar)
galletas$tipo_harina <- as.factor(data_tortas$tipo_harina)
densidad <- c(.90, .87, .90, .86, .89, .91,
.93, .88, .87, .79, .82, .80, # general
.91, .90, .80, .88, .82, .83,
.86, .85, .80, .86, .85, .85) # torta
tipo_harina <- c(rep("general", 12),
rep("para_tortas", 12))
conc_azucar <- c(rep("0", 3), rep("50", 3),
rep("75", 3), rep("100", 3),
rep("0", 3), rep("50", 3),
rep("75", 3), rep("100", 3))
galletas <- data.frame(densidad, tipo_harina, conc_azucar)
galletas$tipo_harina <- as.factor(galletas$tipo_harina)
galletas$conc_azucar <- factor(galletas$conc_azucar,levels = c("0","50","75","100"))
View(galletas)
View(galletas)
galletas_anova <- aov(densidad ~ tipo_harina * conc_azucar, data = galletas)
summary(galletas_anova)
interaction.plot(trace.factor = galletas$tipo_harina,
x.factor = galletas$conc_azucar,
response = galletas$densidad,
fun = "mean",
legend = TRUE,
col = 2:3,
type = "b")
interaction.plot(trace.factor = galletas$conc_azucar,
x.factor = galletas$tipo_harina,
response = galletas$densidad,
fun = "mean",
legend = TRUE,
col = 2:3,
type = "b")
test_supuestos <- function( my_model, nivel_significancia = 0.05 ) {
suppressMessages( require(lmtest) )
suppressMessages( require(car) )
#Shapiro Test
t_sha <- shapiro.test( my_model$residuals )
t_sha_obs <- ifelse( t_sha$p.value > nivel_significancia,
"Los residuos son normales.",
"Los residuos NO son normales.")
#BP Test
t_bp <- bptest( my_model )
t_bp_obs <- ifelse( unname(t_bp$p.value) > nivel_significancia,
"Homocedasticidad. La varianza de los residuos es constante.",
"Heterocedasticidad. La varianza de los residuos NO es constante.")
#Durbin-Watson Test
t_dwt <- durbinWatsonTest( my_model )
t_dwt_obs <- ifelse( t_dwt$p > nivel_significancia,
"No hay autocorrelación. Los residuos son independientes.",
"Hay autocorrelación. Los residuos NO son independientes.")
resultados <- data.frame(
Prueba = c("Shapiro", "Breusch-Pagan", "Durbin-Watson"),
P_Value = c(t_sha$p.value, unname(t_bp$p.value), t_dwt$p)
)
resultados$H0 <- ifelse( resultados$P_Value > nivel_significancia, "No rechazada", "Rechazada" )
resultados$Observaciones <- ifelse( resultados$Prueba == "Shapiro", t_sha_obs,
ifelse( resultados$Prueba == "Breusch-Pagan", t_bp_obs, t_dwt_obs ) )
return(resultados)
}
test_supuestos_aov <- function( my_model, nivel_significancia = 0.05 ) {
suppressMessages( require(lmtest) )
suppressMessages( require(car) )
#Shapiro Test
t_sha <- shapiro.test( my_model$residuals )
t_sha_obs <- ifelse( t_sha$p.value > nivel_significancia,
"Los residuos son normales.",
"Los residuos NO son normales.")
#Levene Test
t_l <- leveneTest( my_model )
t_l_obs <- ifelse( unname(t_l$`Pr(>F)`[1]) > nivel_significancia,
"Homocedasticidad. La varianza de los residuos es constante.",
"Heterocedasticidad. La varianza de los residuos NO es constante.")
resultados <- data.frame(
Prueba = c("Shapiro", "Levene"),
P_Value = c(t_sha$p.value, t_l$`Pr(>F)`[1])
)
resultados$H0 <- ifelse( resultados$P_Value > nivel_significancia, "No rechazada", "Rechazada" )
resultados$Observaciones <- ifelse( resultados$Prueba == "Shapiro", t_sha_obs, t_l_obs )
return(resultados)
}
analizar_vif <- function(modelo) {
suppressMessages( library( car ) )
vif_values <- vif(modelo)
categorias <- ifelse(vif_values <= 1, "Ausente",
ifelse(vif_values <= 5, "Moderada",
"Significativa"))
resultado <- data.frame(Variables = names(vif_values),
VIF = vif_values,
Multicolinealidad = categorias,
row.names = 1:length(vif_values))
return(resultado)
}
outliers_influential_test <- function(model) {
library(dplyr)
# Extracting model information
fitted_values <- model$fitted.values
residuals <- model$residuals
hat_values <- lm.influence(model)$hat
p <- length(model$coefficients)
n <- length(residuals)
# Bonferroni test
bonferroni <- list(which(abs(residuals) > qt(0.975, n-2) * sd(residuals)))
# Cook's distance
cook <- list(which(cooks.distance(model) > 4/(n - p - 1)))
cook2 <- list(which(cooks.distance(model) > 4/n))
# dfbetas
dfbetas <- list(which(abs(dfbetas(model)) > 2/sqrt(n)))
# dffits
dffits <- list(unique(which(dffits(model) > 2 * sqrt(p/n))))
dffits2 <- list(which(abs(dffits(model)) > 2 * sqrt(p * (n - p)/n)))
# Leverage points
leverage_criteria_1 <- 0.2
leverage_criteria_2 <- 2 * p/n
leverage <- list(which(hat_values > leverage_criteria_1 | hat_values > leverage_criteria_2))
# Convert the lists to character strings
bonferroni_str <- toString(unlist(bonferroni))
cook_str <- toString(unlist(cook))
cook_str2 <- toString(unlist(cook2))
dfbetas_str <- toString(unlist(dfbetas))
dffits_str <- toString(unlist(dffits))
dffits_str2 <- toString(unlist(dffits2))
leverage_str <- toString(unlist(leverage))
# Creating a data frame to store the test results
results <- data.frame(
Test_Criteria = c("Bonferroni", "Cook 1", "Cook 2", "DFBetas", "DFFits", "DFFits2", "Leverage"),
Influential_Points = c(bonferroni_str, cook_str, cook_str2, dfbetas_str, dffits_str, dffits_str2, leverage_str),
stringsAsFactors = FALSE
)
return(results)
}
test_supuestos_aov(galletas_anova)
interaction.plot(trace.factor = galletas$tipo_harina,
x.factor = galletas$densidad,
response = galletas$conc_azucar,
fun = "mean",
legend = TRUE,
col = 2:3,
type = "b")
interaction.plot(trace.factor = galletas$tipo_harina,
x.factor = galletas$conc_azucar,
response = galletas$densidad,
fun = "mean",
legend = TRUE,
col = 2:3,
type = "b")
suppressMessages( library( readxl ) )
suppressMessages( library( performance ) )
suppressMessages( library( ggplot2 ) )
suppressMessages( library( MASS ) )
suppressMessages( library( olsrr ) )
suppressMessages( library( leaps ) )
suppressMessages( library( gamlss ) )
suppressMessages( library( readr ) )
suppressMessages( library( gridExtra ) )
suppressMessages( library( vcd ) )
suppressMessages( library( ROCR ) )
suppressMessages( library( ResourceSelection ) )
suppressMessages( library( MLmetrics ) )
suppressMessages( library( caret ) )
test_supuestos <- function( my_model, nivel_significancia = 0.05 ) {
suppressMessages( require(lmtest) )
suppressMessages( require(car) )
#Shapiro Test
t_sha <- shapiro.test( my_model$residuals )
t_sha_obs <- ifelse( t_sha$p.value > nivel_significancia,
"Los residuos son normales.",
"Los residuos NO son normales.")
#BP Test
t_bp <- bptest( my_model )
t_bp_obs <- ifelse( unname(t_bp$p.value) > nivel_significancia,
"Homocedasticidad. La varianza de los residuos es constante.",
"Heterocedasticidad. La varianza de los residuos NO es constante.")
#Durbin-Watson Test
t_dwt <- durbinWatsonTest( my_model )
t_dwt_obs <- ifelse( t_dwt$p > nivel_significancia,
"No hay autocorrelación. Los residuos son independientes.",
"Hay autocorrelación. Los residuos NO son independientes.")
resultados <- data.frame(
Prueba = c("Shapiro", "Breusch-Pagan", "Durbin-Watson"),
P_Value = c(t_sha$p.value, unname(t_bp$p.value), t_dwt$p)
)
resultados$H0 <- ifelse( resultados$P_Value > nivel_significancia, "No rechazada", "Rechazada" )
resultados$Observaciones <- ifelse( resultados$Prueba == "Shapiro", t_sha_obs,
ifelse( resultados$Prueba == "Breusch-Pagan", t_bp_obs, t_dwt_obs ) )
return(resultados)
}
test_supuestos_aov <- function( my_model, nivel_significancia = 0.05 ) {
suppressMessages( require(lmtest) )
suppressMessages( require(car) )
#Shapiro Test
t_sha <- shapiro.test( my_model$residuals )
t_sha_obs <- ifelse( t_sha$p.value > nivel_significancia,
"Los residuos son normales.",
"Los residuos NO son normales.")
#Levene Test
t_l <- leveneTest( my_model )
t_l_obs <- ifelse( unname(t_l$`Pr(>F)`[1]) > nivel_significancia,
"Homocedasticidad. La varianza de los residuos es constante.",
"Heterocedasticidad. La varianza de los residuos NO es constante.")
resultados <- data.frame(
Prueba = c("Shapiro", "Levene"),
P_Value = c(t_sha$p.value, t_l$`Pr(>F)`[1])
)
resultados$H0 <- ifelse( resultados$P_Value > nivel_significancia, "No rechazada", "Rechazada" )
resultados$Observaciones <- ifelse( resultados$Prueba == "Shapiro", t_sha_obs, t_l_obs )
return(resultados)
}
casas <- read_excel("C:/Austral/mcd-reg-adv/datasets/preciocasas.xlsx")
modelo.casas <- lm(precio ~ tamanio, data=casas)
summary(modelo.casas)
test_supuestos(modelo.casas)
check_model( modelo.casas )
ols_plot_resid_lev(modelo.casas, print_plot = TRUE)
plot(casas$precio, casas$tamanio)
text(casas$precio, casas$tamanio, casas$caso, pos = 3)
datos <- casas
datos$predicciones = predict(modelo.casas)
ggplot(datos, aes( x=precio, y=tamanio ) ) +
geom_smooth( method="lm", se=FALSE, color="lightgrey" ) +
geom_segment( aes( xend = precio, yend = predicciones ), col='red', lty='dashed') +
geom_point() +
geom_point( aes( y=predicciones), col='red' ) +
theme_light()
casa_clean <- casas[casas$caso != 64, ]
bc <- boxcox( precio ~ tamanio, lambda = -2:2, data = casa_clean )
lambda <- bc$x[ which.max(bc$y) ]
lambda
modelo.casas3 <- lm( ( ( precio^(lambda) - 1 ) / lambda ) ~ tamanio, data = casa_clean )
summary( modelo.casas3 )
test_supuestos(modelo.casas3)
modelo.casas.robusto <- rlm(precio ~ tamanio, data = casa_clean, psi=psi.huber)
summary(modelo.casas.robusto)
indices_validacion <- sample(nrow(casa_clean), round(0.2 * nrow(casa_clean)))
datos_entrenamiento <- casa_clean[-indices_validacion, ]
datos_validacion <- casa_clean[indices_validacion, ]
modelo.lm <- lm(( ( precio^(lambda) - 1 ) / lambda ) ~ tamanio, data = datos_entrenamiento)
pred.lm <- predict(modelo.lm, newdata = datos_validacion)
#library(caret)
#RMSE(pred.lm, datos_validacion$precio)
lm.resid <- pred.lm - datos_validacion$precio
lm.rmse <- sqrt(mean(lm.resid^2))
modelo.rlm <- rlm( precio ~ tamanio, data = datos_validacion, psi=psi.huber)
pred.rlm <- predict(modelo.rlm, newdata = datos_validacion)
#RMSE(pred.rlm, datos_validacion$precio)
rlm.resid <- rlm_predictions - datos_validacion$precio
indices_validacion <- sample(nrow(casa_clean), round(0.2 * nrow(casa_clean)))
datos_entrenamiento <- casa_clean[-indices_validacion, ]
datos_validacion <- casa_clean[indices_validacion, ]
modelo.lm <- lm(( ( precio^(lambda) - 1 ) / lambda ) ~ tamanio, data = datos_entrenamiento)
pred.lm <- predict(modelo.lm, newdata = datos_validacion)
#library(caret)
#RMSE(pred.lm, datos_validacion$precio)
lm.resid <- pred.lm - datos_validacion$precio
lm.rmse <- sqrt(mean(lm.resid^2))
modelo.rlm <- rlm( precio ~ tamanio, data = datos_validacion, psi=psi.huber)
pred.rlm <- predict(modelo.rlm, newdata = datos_validacion)
#RMSE(pred.rlm, datos_validacion$precio)
rlm.resid <- pred.rlm - datos_validacion$precio
rlm.rmse <- sqrt(mean(rlm_residuals^2))
indices_validacion <- sample(nrow(casa_clean), round(0.2 * nrow(casa_clean)))
datos_entrenamiento <- casa_clean[-indices_validacion, ]
datos_validacion <- casa_clean[indices_validacion, ]
modelo.lm <- lm(( ( precio^(lambda) - 1 ) / lambda ) ~ tamanio, data = datos_entrenamiento)
pred.lm <- predict(modelo.lm, newdata = datos_validacion)
#library(caret)
#RMSE(pred.lm, datos_validacion$precio)
lm.resid <- pred.lm - datos_validacion$precio
lm.rmse <- sqrt(mean(lm.resid^2))
modelo.rlm <- rlm( precio ~ tamanio, data = datos_validacion, psi=psi.huber)
pred.rlm <- predict(modelo.rlm, newdata = datos_validacion)
#RMSE(pred.rlm, datos_validacion$precio)
rlm.resid <- pred.rlm - datos_validacion$precio
rlm.rmse <- sqrt(mean(rlm.resid^2))
print(paste("LM RSME:", lm.rmse))
print(paste("RLM RSME:", rlm.rmse))
indices_validacion <- sample(nrow(casa_clean), round(0.2 * nrow(casa_clean)))
datos_entrenamiento <- casa_clean[-indices_validacion, ]
datos_validacion <- casa_clean[indices_validacion, ]
modelo.lm <- lm(( ( precio^(lambda) - 1 ) / lambda ) ~ tamanio, data = datos_entrenamiento)
pred.lm <- predict(modelo.lm, newdata = datos_validacion)
#library(caret)
#RMSE(pred.lm, datos_validacion$precio)
lm.resid <- pred.lm - datos_validacion$precio
lm.rmse <- mean(lm.resid^2
modelo.rlm <- rlm( precio ~ tamanio, data = datos_validacion, psi=psi.huber)
indices_validacion <- sample(nrow(casa_clean), round(0.2 * nrow(casa_clean)))
datos_entrenamiento <- casa_clean[-indices_validacion, ]
datos_validacion <- casa_clean[indices_validacion, ]
modelo.lm <- lm(( ( precio^(lambda) - 1 ) / lambda ) ~ tamanio, data = datos_entrenamiento)
pred.lm <- predict(modelo.lm, newdata = datos_validacion)
#library(caret)
#RMSE(pred.lm, datos_validacion$precio)
lm.resid <- pred.lm - datos_validacion$precio
lm.rmse <- mean(lm.resid^2)
modelo.rlm <- rlm( precio ~ tamanio, data = datos_validacion, psi=psi.huber)
pred.rlm <- predict(modelo.rlm, newdata = datos_validacion)
#RMSE(pred.rlm, datos_validacion$precio)
rlm.resid <- pred.rlm - datos_validacion$precio
rlm.rmse <- mean(rlm.resid^2)
print(paste("LM RSME:", lm.rmse))
print(paste("RLM RSME:", rlm.rmse))
indices_validacion <- sample(nrow(casa_clean), round(0.2 * nrow(casa_clean)))
datos_entrenamiento <- casa_clean[-indices_validacion, ]
datos_validacion <- casa_clean[indices_validacion, ]
modelo.lm <- lm(( ( precio^(lambda) - 1 ) / lambda ) ~ tamanio, data = datos_entrenamiento)
pred.lm <- predict(modelo.lm, newdata = datos_validacion)
#library(caret)
#RMSE(pred.lm, datos_validacion$precio)
lm.resid <- pred.lm - datos_validacion$precio
lm.rmse <- sqrt(mean(lm.resid^2))
modelo.rlm <- rlm( precio ~ tamanio, data = datos_validacion, psi=psi.huber)
pred.rlm <- predict(modelo.rlm, newdata = datos_validacion)
#RMSE(pred.rlm, datos_validacion$precio)
rlm.resid <- pred.rlm - datos_validacion$precio
rlm.rmse <- sqrt(mean(rlm.resid^2))
print(paste("LM RSME:", lm.rmse))
print(paste("RLM RSME:", rlm.rmse))
print(paste("RLM RSME:", round(rlm.rmse,2))()
indices_validacion <- sample(nrow(casa_clean), round(0.2 * nrow(casa_clean)))
indices_validacion <- sample(nrow(casa_clean), round(0.2 * nrow(casa_clean)))
datos_entrenamiento <- casa_clean[-indices_validacion, ]
datos_validacion <- casa_clean[indices_validacion, ]
modelo.lm <- lm(( ( precio^(lambda) - 1 ) / lambda ) ~ tamanio, data = datos_entrenamiento)
pred.lm <- predict(modelo.lm, newdata = datos_validacion)
#library(caret)
#RMSE(pred.lm, datos_validacion$precio)
lm.resid <- pred.lm - datos_validacion$precio
lm.rmse <- sqrt(mean(lm.resid^2))
modelo.rlm <- rlm( precio ~ tamanio, data = datos_validacion, psi=psi.huber)
pred.rlm <- predict(modelo.rlm, newdata = datos_validacion)
#RMSE(pred.rlm, datos_validacion$precio)
rlm.resid <- pred.rlm - datos_validacion$precio
rlm.rmse <- sqrt(mean(rlm.resid^2))
print(paste("LM RSME:", round(lm.rmse,2)))
print(paste("RLM RSME:", round(rlm.rmse,2)))
